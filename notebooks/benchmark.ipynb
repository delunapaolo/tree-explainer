{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Introduction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install packages\n",
    "\n",
    "Install treeinterpreter ([source](https://github.com/andosa/treeinterpreter/)) with:\n",
    "\n",
    "    pip install treeinterpreter\n",
    "\n",
    "Install ELI5 ([source](https://github.com/TeamHG-Memex/eli5)) with:\n",
    "\n",
    "    pip install eli5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TreeExplainer produces the same values of treeinterpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from treeinterpreter import treeinterpreter as ti\n",
    "from tree_explainer.tree_explainer import TreeExplainer\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "\n",
    "SEED = 17\n",
    "\n",
    "# Generate data\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_classes=2)\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.20, random_state=SEED)\n",
    "\n",
    "# Create and train classifier\n",
    "RF = RandomForestClassifier(n_estimators=100, random_state=SEED, n_jobs=-1)\n",
    "RF.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 104 ms, sys: 4.48 ms, total: 108 ms\n",
      "Wall time: 106 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# Use treeinterpreter to compute feature contributions\n",
    "# Call directly _predict_forest()\n",
    "ti_prediction, ti_bias, ti_contributions = ti._predict_forest(RF, X_test, joint_contribution=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.2 ms, sys: 6.85 ms, total: 32 ms\n",
      "Wall time: 110 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Initialize TreeExplainer\n",
    "TE = TreeExplainer(RF, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 323 ms, sys: 3.83 ms, total: 327 ms\n",
      "Wall time: 325 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tree_explainer.tree_explainer.TreeExplainer at 0x1a18f134a8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Compute feature contributions\n",
    "TE.explain_feature_contributions(joint_contributions=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that results are the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Are contribution values the same?\n",
    "np.allclose(TE.contributions, \n",
    "            ti_contributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Are the target probabilities at the root of each tree the same?\n",
    "np.allclose(TE.target_probability_at_root.mean(axis=0), \n",
    "            ti_bias[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Are predicted values the same?\n",
    "np.allclose(TE.prediction_probabilities, \n",
    "            ti_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do predictions equal the sum of feature contributions and target probabilities at the root of each tree?\n",
    "np.allclose(ti_prediction, \n",
    "            np.sum(ti_contributions, axis=1) + ti_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do predictions equal the sum of feature contributions and target probabilities at the root of each tree?\n",
    "np.allclose(TE.prediction_probabilities, \n",
    "            np.sum(TE.contributions, axis=1) + TE.target_probability_at_root.mean(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELI5 is cumbersome and slow, but offers a colorful output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.3 s, sys: 1.63 s, total: 17.9 s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from eli5.sklearn.explain_prediction import explain_prediction_tree_classifier\n",
    "from eli5.formatters.as_dataframe import format_as_dataframe\n",
    "\n",
    "\n",
    "# Iterate through each observation\n",
    "RES = list()\n",
    "for i_obs in range(X_test.shape[0]):\n",
    "    res = format_as_dataframe(explain_prediction_tree_classifier(RF, X_test[i_obs, :]))\n",
    "    # Add index of observation\n",
    "    res['observation'] = i_obs\n",
    "    RES.append(res)\n",
    "\n",
    "# Concatenate results\n",
    "all_RES = pd.concat(RES, axis=0, ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eli5_contributions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-adb44a51a60e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Check target probability at root\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m print(np.allclose(ti_bias[0, :], \n\u001b[0;32m----> 3\u001b[0;31m                   eli5_contributions.loc['<BIAS>'].values))\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m print(np.allclose(TE.target_probability_at_root.mean(axis=0), \n",
      "\u001b[0;31mNameError\u001b[0m: name 'eli5_contributions' is not defined"
     ]
    }
   ],
   "source": [
    "# Check target probability at root\n",
    "print(np.allclose(ti_bias[0, :], \n",
    "                  eli5_contributions.loc['<BIAS>'].values))\n",
    "\n",
    "print(np.allclose(TE.target_probability_at_root.mean(axis=0), \n",
    "                  eli5_contributions.loc['<BIAS>'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that predictions are the same\n",
    "eli5_predictions = all_RES.groupby(by=['observation', 'target'])['weight'].sum()\n",
    "rows = eli5_predictions.to_frame().reset_index()['observation'].values\n",
    "cols = eli5_predictions.to_frame().reset_index()['target'].values\n",
    "\n",
    "print(np.allclose(ti_prediction[rows, cols], \n",
    "                  eli5_predictions.values))\n",
    "\n",
    "print(np.allclose(TE.prediction_probabilities[rows, cols], \n",
    "                  eli5_predictions.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5_contributions = (all_RES\n",
    "                      .groupby(by=['feature', 'target'])['weight']\n",
    "                      .mean()\n",
    "                      .to_frame()\n",
    "                      .reset_index()\n",
    "                      .pivot(index='feature', columns='target', values='weight')\n",
    "                      .values[1:, :]  # first row refers to <BIAS>\n",
    "                     )\n",
    "\n",
    "eli5_contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These values are completely different from treeinterpreter, and more importantly, they are not symmetric, that is, the average contribution to a target does not correspond to an equal weight in the opposite direction to the other target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ti_contributions.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, eli5 does not use information from true labels. This means, that the average contribution values refer to the predicted targets. If we group contributions by predicted targets, the results are the same of treeinterpreter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_targets = ti_prediction.argmax(axis=1) \n",
    "ti_contributions_by_predicted_target = np.vstack((ti_contributions[predicted_targets == 0, :, 0].mean(0), \n",
    "                                                  ti_contributions[predicted_targets == 1, :, 1].mean(0))).T\n",
    "\n",
    "np.allclose(ti_contributions_by_predicted_target, \n",
    "            eli5_contributions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite all (!), ELI5 offers a colorful output (in a Jupyter notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eli5 import show_prediction\n",
    "\n",
    "# Again, one observation at a time. Let's see observation number 1\n",
    "show_prediction(RF, X_test[0, :], show_feature_values=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you can live without colors, TreeExplainer offers a similar interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform X_test into a DataFrame, so we can use the same feature names as in ELI5\n",
    "df_test = pd.DataFrame(X_test, columns=['x%i' % i for i in range(X_test.shape[1])])\n",
    "\n",
    "# Rerun TreeExplainer by passing joint_contributions = True\n",
    "TE = TreeExplainer(RF, df_test, y_test).explain_feature_contributions(joint_contributions=True);\n",
    "# Let's analyze the rest of the tree structure\n",
    "TE.analyze_tree_structure();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see observation number 1\n",
    "TE.explain_single_prediction(observation_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TreeExplainer outputs the `value` of the observation, alongside the confidence of the model (as quartiles) regarding the range of values that of a feature falling in the target class. The last column shows the contribution of each feature, in terms of percentage to the final decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "treeinterpreter is fast and simple. If you only need the values of feature contributions, it is the best option of the 3 tested here.\n",
    "\n",
    "TreeExplainer offers more advanced features, and to do so it holds and scans the tree structure more thoroughly. This comes at a cost in speed. Most analyses can be carried on in parallel, but (in my experience) this hardly reduces the time of computations. Rather, the overhead is usually slowing the algorithm, but your mileage may vary. More advanced options are available in most methods of this class, which port ideas of R packages to python.\n",
    "\n",
    "ELI5 offers many options, including more advanced ones, such as LIME. However, it is slow, and it doesn't support the inspection of a whole dataset. Moreover, even after looping through all observations, it is cumbersome to obtain average values of feature contributions. If you are simply after feature contributions, go for treeinterpreter; if you want to try LIME, just do so, instead of relying on a third party library; for all other cases, there are better libraries than ELI5, and TreeExplainer might do for you."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
